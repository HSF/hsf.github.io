<!DOCTYPE html>
<html>
<head lang="en">
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1 user-scalable=no">
    <title>Acts GPU R&D - Optimization of GPU tracking pipeline</title>
    <link rel="icon" type="image/x-icon" href="/images/hsf_logo_angled.png">

    <!-- bootstrap framework -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootswatch/3.3.5/flatly/bootstrap.min.css">

    <link rel="stylesheet" href="/css/hsf.css" type="text/css" />
</head>
<body>

<div class="navbar navbar-default">
    <div class="container">
        <div class="navbar-header">
          <a href="/" class="navbar-brand"><span class="glyphicon glyphicon-home"></span>&nbsp;&nbsp;HSF</a>
          <button class="navbar-toggle" type="button" data-toggle="collapse" data-target="#navbar-main">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
        </div>
        <div class="navbar-collapse collapse" id="navbar-main">
          <ul class="nav navbar-nav navbar-center">
            <li class="dropdown">
              <a class="dropdown-toggle" data-toggle="dropdown" href="/index.html" id="wg_menu"><span class="glyphicon glyphicon-briefcase"></span>&nbsp;&nbsp;Working Groups<span class="caret"></span></a>
                <ul class="dropdown-menu" aria-labelledby="activities_menu">
                  <li><a href="/what_are_WGs.html">What are HSF working groups?</a></li>
                  <li class="divider"></li>
                  
                    <li><a href="/workinggroups/dataanalysis.html">Data Analysis</a></li>
                  
                    <li><a href="/workinggroups/detsim.html">Detector Simulation</a></li>
                  
                    <li><a href="/workinggroups/frameworks.html">Frameworks</a></li>
                  
                    <li><a href="/workinggroups/generators.html">Physics Generators</a></li>
                  
                    <li><a href="/workinggroups/juliahep.html">JuliaHEP - Julia in HEP</a></li>
                  
                    <li><a href="/workinggroups/pyhep.html">PyHEP - Python in HEP</a></li>
                  
                    <li><a href="/workinggroups/recotrigger.html">Reconstruction and Software Triggers</a></li>
                  
                    <li><a href="/workinggroups/toolsandpackaging.html">Software Developer Tools and Packaging</a></li>
                  
                    <li><a href="/workinggroups/training.html">HSF Training</a></li>
                  
               </ul>
            </li>
            <li class="dropdown">
              <a class="dropdown-toggle" data-toggle="dropdown" href="/index.html" id="activities_menu"><span class="glyphicon glyphicon-briefcase"></span>&nbsp;&nbsp;Activities<span class="caret"></span></a>
                <ul class="dropdown-menu" aria-labelledby="activities_menu">
                 <li><a href="/what_are_activities.html">What are HSF activity areas?</a></li>
                 <li class="divider"></li>
                 
                   <li><a href="/activities/analysisfacilitiesforum.html">Analysis Facilities Forum</a></li>
                 
                   <li><a href="/activities/conditionsdb.html">Conditions Databases</a></li>
                 
                   <li><a href="/activities/differentiablecomputing.html">Differentiable Computing</a></li>
                 
                   <li><a href="/activities/gsdocs.html">Season of Docs</a></li>
                 
                   <li><a href="/activities/gsoc.html">Google Summer of Code</a></li>
                 
                   <li><a href="/activities/idds.html">intelligent Data Delivery Service</a></li>
                 
                   <li><a href="/activities/licensing.html">Licensing</a></li>
                 
                   <li><a href="/activities/reviews.html">Reviews</a></li>
                 
                   <li><a href="/activities/visualization.html">Visualisation</a></li>
                 
               </ul>
            </li>
            <li class="dropdown">
              <a class="dropdown-toggle" data-toggle="dropdown" href="/index.html" id="meetings_menu"><span class="glyphicon glyphicon-phone-alt"></span>&nbsp;&nbsp;Meetings<span class="caret"></span></a>
                <ul class="dropdown-menu" aria-labelledby="activities_menu">
                 
                   <li><a href="/meetings/compute-accelerator-forum.html">Compute Accelerator Forum</a></li>
                 
                   <li><a href="/meetings/coordination.html">Coordination Meetings</a></li>
                 
                   <li><a href="/meetings/roundtable.html">Software and Computing Roundtable</a></li>
                 
                   <li><a href="/meetings/software-forum.html">Software Forum</a></li>
                 
               </ul>
            </li>
            <li class="dropdown">
              <a class="dropdown-toggle" data-toggle="dropdown" href="/index.html" id="communication_menu"><span class="glyphicon glyphicon-bullhorn"></span>&nbsp;&nbsp;Communication<span class="caret"></span></a>
                <ul class="dropdown-menu" aria-labelledby="communication_menu">
                  <li><a href="/future-events.html">Community Calendar</a></li>
                  <li><a href="https://indico.cern.ch/category/5816/" target="_hsf_indico">Meetings: Indico</a></li>
                  <li><a href="/Schools/events.html">Training Schools</a></li>
                  <li class="divider"></li>
                  <li><a href="/forums.html">Mailing Lists and Forums</a></li>
                  <li><a href="/organization/minutes.html">Meeting Notes</a></li>
                  <li><a href="/technical_notes.html">Technical Notes</a></li>
                  <li><a href="/organization/documents.html">Documents</a></li>
                  <li><a href="/material_for_presentations.html">Material for presentations</a></li>
                  <li class="divider"></li>
                  <li><a href="/newsletter.html">Newsletters</a></li>
                  <li><a href="/events.html">Events &amp; Workshops</a></li>
                  <li><a href="https://www.youtube.com/c/HEPSoftwareFoundation" target="_hsf_youtube">HSF on YouTube</a></li>
                  <li class="divider"></li>

                  <li><a href="/inventory/inventory.html">HSF Project Inventory</a></li>
                </ul>
            </li>
            <li class="dropdown">
              <a class="dropdown-toggle" data-toggle="dropdown" href="/projects.html" id="projects_menu"><span class="glyphicon glyphicon-road"></span>&nbsp;&nbsp;Projects &amp; Support<span class="caret"></span></a>
                <ul class="dropdown-menu" aria-labelledby="projects_menu">
                  <li><a href="/project_guidelines.html">How to join as a project</a></li>
                  <li><a href="/projects.html">Member Projects</a></li>
                  <li class="divider"></li>
                  <li><a href="/services.html">Development Services</a></li>
                </ul>
            </li>
          </ul>
          <ul class="nav navbar-nav navbar-right">
            <li class="dropdown">
              <a class="dropdown-toggle" data-toggle="dropdown" href="/index.html" id="about_menu"><span class="glyphicon glyphicon-info-sign"></span>&nbsp;&nbsp;About<span class="caret"></span></a>
              <ul class="dropdown-menu" aria-labelledby="about_menu">
                <li><a href="/get_involved.html">Get involved!</a><li>
                <li><a href="/organization/team.html">The Coordination Team</a></li>
                <li><a href="/organization/planning/plan-of-work-2023.html">HSF Planning</a></li>
                <li class="divider"></li>
                <li><a href="/organization/goals.html">Goals of the HSF</a></li>
                <li><a href="/organization/cwp.html">Community White Paper</a></li>
                <li><a href="/organization/hsf-letters.html">Letters from the HSF</a></li>
                <li><a href="/organization/presentations.html">HSF Presentations</a></li>
                <li><a href="/organization/youtube.html">HSF YouTube Channel</a></li>
                <li class="divider"></li>
                <li><a href="/howto-website.html">Website Howto</a></li>
              </ul>
            </li>
          </ul>
        </div>
    </div>
</div>


<div class="container">

  <div class="PageNavigation">

  <!-- Note that page sorting is reverse time ordered, so "next" refers to the previous
       meeting in time and "previous" to the next one -->
  
   <p class="alignleft"><a href="/gsoc/blogs/2022/blog_TMVADevelopments_HarshalShende.html">&nbsp;&#8592; Improve Python interface for TMVA</a></p>
  

  
    <p class="alignright"><a href="/gsoc/blogs/2022/blog_Geant4_DivyanshTiwari.html">Symplectic Integrators &#8594;&nbsp;</a></p>
  

</div>

<div style="clear: both;"></div>


<hr>

<div class="blog-header">
  <div class="row">
    
       
        <div class="col-md-3">
          <img src="/images/blog_authors/KavishkaAttanayake.jpeg" alt=Kavishka Attanayake width="100%" style="float:right">
        </div>
        <div class="col-md-9">
      
    
    <h1 class="blog-title">Acts GPU R&D - Optimization of GPU tracking pipeline</h1>
    </div>
  </div>
  <p class="blog-post-meta">26 Jul 2022 by <a href="/gsoc/blogs/2022/blog_Acts_KavishkaAttanayake.html">Kavishka Attanayake</a></p>
</div>

<div class="row">
  <div class="col-sm-12 blog-main">

  <h1 id="acts-gpu-rd---optimization-of-gpu-tracking-pipeline">Acts GPU R&amp;D - Optimization of GPU tracking pipeline</h1>

<h3 id="dear-future-readers">Dear future readers</h3>

<p>Hey all! As of starting GSoC 2022 I am a third year undergraduate from the University of Moratuwa, Sri Lanka. GSoC program was an excellent way to get started with open source and explore technology/fields that interest you with the help of experienced mentors. Personally, astrophysics was something I was really curious about since I was a little kid, this was one main reason I chose to contribute under CERN. Moreover CUDA was not completely new to me therefore, I found this project a good fit. It’s okay to not know about everything, there were many new concepts to me which I understood along the way.</p>

<p>If you are a potential future contributor, I suggest that communication is the most important skill that’s required. If you are having a difficulty your mentors are always willing to help you out!</p>

<h2 id="project-description">Project Description</h2>
<h5 id="mentors-beomki-yeo--charles-leggett">Mentors: Beomki Yeo &amp; Charles Leggett</h5>

<p>Acts is a track reconstruction software toolkit for high energy physics experiments. With the increasing number of particle interactions in the HL-LHC 
experiments in the future the track reconstruction time will also increase. GPU R&amp;D is conducted under traccc, vecmem and detray to accelerate the track 
reconstruction. Vecmem provides memory management tools for convenient GPU memory management and caching allocators, Detray is a geometry builder which 
translates the CPU geometry into GPU one (did not get my head around this one yet.) and finally Traccc demonstrates the gpu tracking pipeline.</p>

<p>This project mainly focuses on improving the throughput of the Traccc pipeline. This is achieved by using CUDA-MPS or CUDA-MIG and utilizing caching 
allocators provided by Vecmem.</p>

<p>Comprehensive introduction and progress :</p>
<ul>
  <li><a href="https://medium.com/@attanayakekavishka/optimization-of-gpu-tracking-pipeline-for-acts-gpu-r-d-part-1-4b7e9ac6379d">mid report</a></li>
  <li><a href="https://chamodya-ka.github.io/blog/GSOC-2022/">complete report</a>
    <h3 id="communication-with-the-mentors-and-the-community">Communication with the mentors and the community</h3>
  </li>
</ul>

<h4 id="weekly-meetings-with-the-mentors">Weekly meetings with the mentors</h4>

<p>Weekly meetings were held every week (Thursdays) with the mentors starting from May 26th. Here my weekly progress, doubts and plans for the next week
were discussed.</p>

<h4 id="bi-weekly-acts-parallelization-group-meeting">Bi-weekly Acts Parallelization Group meeting</h4>

<p>Bi weekly group meetings where contributors from different organizations and institutes discuss their updates. Moreover, discussions on any new projects are
carried out. Understanding everything that is being discussed is a big challenge, nonetheless it is enjoyable listening to such an enthusiastic crowd.
This is a valuable opportunity for me to grasp what’s going on in the community and also learn from their discussions.</p>

<h2 id="progress">Progress</h2>
<h4 id="weeks-1-4--including-community-bonding-">Weeks 1-4 ( including community bonding )</h4>
<blockquote>
  <p>Ending on 16.06.2022</p>
</blockquote>

<p>CUDA-MPS was something relatively new to me at the time, I had tested CUDA-MPS during the application period and continued this work over during community bonding. Joined my first parallelization group meeting, gave me the opportunity to see and listen to the developers and introduce myself as well. Meanwhile started working on porting SYCL clusterization code to CUDA and created a <a href="https://github.com/acts-project/traccc/pull/206">PR (PR-206)</a>. This PR was not merged in as it was outdated at the time, nevertheless it was a great starting point and got valuable feedback from the community.
Moreover, my mentors provided access to a server at Lawrence Berkeley National Laboratory to conduct the benchmarking.</p>

<h4 id="weeks-5-8">Weeks 5-8</h4>
<blockquote>
  <p>Ending on 14.07.2022</p>
</blockquote>

<p>Modified the PR-206 to fit in with the latest version and added suggested changes, this was merged in <a href="https://github.com/acts-project/traccc/pull/209">PR-209</a>.
Tests were done using caching allocators, and there were issues along the way (<a href="https://github.com/acts-project/vecmem/issues/180">issue with contiguous memory resource</a> and issue with <a href="https://github.com/acts-project/vecmem/issues/182">binary page memory resource</a>), Once the issues were fixed by the Vecmem developers. I carried out benchmarks using contiguous memory resource and got expected results. Sadly, using binary page memory resource did worse than using any caching allocation at all. Therefore, benchmarking throughput with caching allocators was postponed. Meanwhile, a way to use Contiguous memory resource as an alternative will be explored. In addition, prepared the bash scripts and modified the CUDA algorithm to be suitable for benchmarking and comparing against the CPU algorithm.</p>

<h4 id="weeks-9-10">Weeks 9-10</h4>
<blockquote>
  <p>Ending on 28.07.2022 (Mid Evaluation)</p>
</blockquote>

<p>Benchmarked overall throughput for the CPU algorithm and CUDA algorithm with and without MPS <a href="https://drive.google.com/drive/folders/15QFPNNwgh75RoRZ2au2_WybCuIMbUQpQ">logs available here</a>. Speed up by using MPS can be expected only from this kernel execution and memory transfer portion. Therefore, significant improvement was not observable by using MPS, since CUDA kernel execution only takes up ~10% of the entire process. As advised by my mentors I started benchmarking kernel level throughput with and without MPS. Currently I have completed benchmarking and in the process of analyzing the kernel execution times. After this analysis it will provide more insight into how the number of processes will affect the individual kernel throughput.</p>

<p>Following are two comparisons between using MPS and not using MPS each process computes 10 and 150 events respectively. X axis is the number of processes that are running concurrently. Y axis is the throughput in events/second</p>

<p><img src="https://user-images.githubusercontent.com/58067288/181102393-bf893de6-492d-4c5c-8187-3c3db2eeff49.jpg" alt="10_events" />
<img src="https://user-images.githubusercontent.com/58067288/181108051-5f3bdd22-6d23-46cc-b764-4ccb6661a169.jpg" alt="150_events" /></p>

<h4 id="weeks-11-14">Weeks 11-14</h4>
<blockquote>
  <p>Ending on 25.08.2022</p>
</blockquote>

<p>The plots on the kernel level execution were cluttered as there was no synchronization before each kernel execution among the concurrent processes. During the first two weeks, I worked on using shared memory to implement inter process communication to synchronize the concurrent processes and obtained the execution times. However, interpreting the results required help from my mentors, this will be discussed later. 
Moreover, benchmarks were carried out on the overall pipeline using vecmem caching allocators and multiple memory resources. Similar benchmarks were conducted to find how many events per process would give the peak throughput. The results will be discussed below. I was given the opportunity to present my progress and contributions at the ACTS parallelization group meeting as well.</p>

<h3 id="results">Results</h3>
<h4 id="throughput-benchmarks">Throughput benchmarks</h4>
<p>Comparison between different memory resources is shown below.</p>

<p><img src="https://user-images.githubusercontent.com/58067288/189314296-e8d48284-69ab-4b9a-9664-36eb237fdba4.jpg" alt="mem_res_mps_comparision" /></p>

<p>By utilizing contiguous memory resource with CUDA pinned memory upstream, the effect of CUDA mps is significant compared to when using only managed memory(see the plots under week 9-10).
<img src="https://user-images.githubusercontent.com/58067288/189314610-236667f5-956b-465f-aa68-ab5d6e12321c.png" alt="c_mr_mps_comp" /></p>

<p>The plot below shows a throughput comparison between multicore CPU and CUDA-MPS.
<img src="https://user-images.githubusercontent.com/58067288/189314831-08131ba8-1f8d-4da2-a683-965f503f387b.png" alt="mps_cuda_cpu" /></p>

<h4 id="kernel-level-benchmarks">Kernel level benchmarks</h4>

<p>The following is a single kernel execution time plot for the spacepoint formation kernel against the number of concurrently running processes.
<img src="https://user-images.githubusercontent.com/58067288/189314421-87f4c0ac-391b-445b-be53-1b2647f811b5.png" alt="form_spacepoints" /></p>

<p>The sudden increase in times from 2 to 3 processes can be explained as there are 2 GPUs and introducing a third process can cause a single GPU to work almost twice as long stretching the wait time for all 3 processes. Similar case when there are 4 processes, now each GPU works twice as long. However this trend does not continue over when the number of processes increase further, this can be explained as a one time overhead as GPU context switching is introduced for the first time.</p>

<h3 id="conclusion">Conclusion</h3>

<p>This concludes my GSoC adventure, I got the opportunity to contribute to CERN as well as learn CUDA further. Moreover the interaction with my mentors was helpful to improve my soft skills too!</p>



   </div>
</div>


<br><br>
<hr>
<div class="footer fixed-bottom">
<a href="https://github.com/HSF/hsf.github.io/edit/main/_gsocblogs/2022/blog_Acts_KavishkaAttanayake.md"><i class="glyphicon glyphicon-wrench"></i> Improve this page. </a>
Thanks to <a href="https://pages.github.com/">GitHub Pages</a>, <a href="http://jekyllrb.com/">Jekyll</a> and <a href="http://getbootstrap.com/">Bootstrap</a>.
</div>

</div> <!-- container -->


<!-- Google Analytics -->

<!-- Google Analytics end -->

<script src="https://code.jquery.com/jquery-2.1.4.min.js"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js"></script>
</body>
</html>
